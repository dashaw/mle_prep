## [Course link](https://www.coursera.org/learn/machine-learning/home/welcome)

## Gradient descent

* batch = using all samples for update step

## Vectorization

* remember lower-level detail of how we use vectorization/matrix multiplication 
* e.g., going from $f_{w,b}(x) = w_{1}*x_{1} + w_{2}*x_{2} + b$ --> $f_{w,b}(\vec{x}) = \vec{w} \cdot \vec{x} + b$ 
