## [Course link](https://www.coursera.org/learn/machine-learning/home/welcome)

## Gradient descent

* batch = using all samples for update step

## Vectorization

* remember lower-level detail of how we use vectorization/matrix multiplication * e.g., going from $f_{w,b}(x) = w_1*x_1 + w_2*x_2 + b$ --> $f_{w,b}(\vec{x}) = \vec{w} \cdot \vec{x} + b$ 
